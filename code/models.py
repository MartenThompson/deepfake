import csvfrom datetime import datetimeimport osimport numpy as npfrom sklearn.metrics import roc_auc_scorefrom sklearn.metrics import roc_curveimport tensorflow as tftf.config.threading.set_inter_op_parallelism_threads(20)tf.config.threading.set_intra_op_parallelism_threads(20)tf.random.set_seed(8008)np.random.seed(808)from tensorflow import kerasfrom tensorflow.keras import layersfrom data_mgmt import make_2D_datasets#import pydot#import graphvizclass modelContainer():    def __init__(self, name, trained_model, training_history, test_accuracy, roc_data, auc):        timestamp = datetime.now().strftime('%Y_%m_%d_%H')        self.name = name + timestamp        self.model = trained_model        self.history = training_history        self.test_accuracy = test_accuracy        self.roc_data = roc_data        self.auc = auc            def save(self):        self.model.save('../saved_models/'+self.name)                loss = self.history.history['loss']        accr = self.history.history['accuracy']        file_contents = np.array([loss, accr]).T        filename = '../visualization/plotting_data/'+self.name+'_training_history.csv'        file = open(filename, 'w+', newline ='')           with file:            write = csv.writer(file)            write.writerows(file_contents)                file_contents = [self.test_accuracy]        filename = '../visualization/plotting_data/'+self.name+'_testing_history.csv'        file = open(filename, 'w+', newline ='')           with file:            write = csv.writer(file)            write.writerows(file_contents)                    file_contents = self.roc_data        filename = '../visualization/plotting_data/'+self.name+'_roc_data.csv'        file = open(filename, 'w+', newline ='')           with file:            write = csv.writer(file)            write.writerows(file_contents)                np.save('../visualization/plotting_data/'+self.name+'_auc.npy', np.array(self.auc))class modelContainer2():    def __init__(self, name, trained_model, training_history, roc_data, auc):        timestamp = datetime.now().strftime('%Y_%m_%d_%H')        self.name = name + timestamp        self.model = trained_model        self.history = training_history        self.roc_data = roc_data        self.auc = auc            def save(self):        self.model.save('../saved_models/'+self.name)                loss = self.history.history['loss']        accr = self.history.history['accuracy']        val_l = self.history.history['val_loss']        val_a = self.history.history['val_accuracy']        file_contents = np.array([loss, accr, val_l, val_a]).T        filename = '../visualization/plotting_data/'+self.name+'_training_history.csv'        file = open(filename, 'w+', newline ='')           with file:            write = csv.writer(file)            write.writerows(file_contents)                            file_contents = self.roc_data        filename = '../visualization/plotting_data/'+self.name+'_roc_data.csv'        file = open(filename, 'w+', newline ='')           with file:            write = csv.writer(file)            write.writerows(file_contents)                np.save('../visualization/plotting_data/'+self.name+'_auc.npy', np.array(self.auc))def cnn2D(n_epoch, batch_size, img_hw, root_dir, trace=False):    '''    Batch size determined by train_ds         Input: 3D tensor (2D images w/ 3 channels)    Network:         Dense       2 nodes        Dense       128 nodes        Flatten        MaxPool2D   (2, 2, 2) pool        Conv2D      32 filters, saf(3,3,3) kernel, ReLU        MaxPool2D   (2, 2, 2) pool        Conv2D      32 filters, (3,3,3) kernel, ReLU        MaxPool2D   (2, 2, 2) pool        Conv2D      32 filters, (3,3,3) kernel, ReLU        Rescaling   [-1,1]    '''        [train_ds, test_ds] = make_2D_datasets(batch_size, img_hw, root_dir)            inputs = keras.Input(shape=(img_hw, img_hw, 3,)) # omit specifying batch size explicitly    x = layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1)(inputs) # or just 1./255    x = layers.Conv2D(32, 3, activation='relu')(x)    #x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu')(x)    #x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu')(x)    x = layers.MaxPooling2D()(x)    x = layers.Flatten()(x)    x = layers.Dropout(0.5)(x)    x = layers.Dense(64, activation='relu')(x)    x = layers.Dropout(0.5)(x)    outputs = layers.Dense(2)(x)        model = keras.Model(inputs=inputs, outputs=outputs, name='basic_cnn')    #model.summary()    #keras.utils.plot_model(model, 'cnn2D_vert.png', show_shapes=False, show_layer_names=False, rankdir='TB')        model.compile(        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),        #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),        optimizer=keras.optimizers.RMSprop(),        metrics=['accuracy'],    )        if trace:        print('Training CNN 2D')    history = model.fit(train_ds, validation_data=test_ds, epochs=n_epoch, verbose=1)        #if trace:    #    print('Testing CNN 2D')    # test accuracy and lost    #test_accr = model.evaluate(test_ds, verbose=1)        # can't use metric='AUC' with Dense(2)    y_pred = tf.nn.softmax(model.predict(test_ds))[:,1] # sklearn just takes prob of larger label        y_test = []    for x,y in test_ds:        y_test = y_test+y.numpy().tolist()        auc = roc_auc_score(y_test, y_pred)    false_pos, true_pos, thresholds = roc_curve(y_test, y_pred)        roc_data = np.array([false_pos, true_pos, thresholds]).T        m = modelContainer2('cnn2D_model', model, history, roc_data, auc)        return(m)def pad_depth(x, desired_channels):    y = tf.keras.backend.zeros_like(x)    new_channels = desired_channels - x.shape.as_list()[-1]    y = y[..., :new_channels]    return tf.keras.backend.concatenate([x, y], axis=-1)def cnn2D_deep(n_epoch, batch_size, img_hw, root_dir, trace=False):        [train_ds, test_ds] = make_2D_datasets(batch_size, img_hw, root_dir)         inputs = keras.Input(shape=(img_hw, img_hw, 3,)) # omit specifying batch size explicitly    x = layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1)(inputs) # or just 1./255    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.MaxPooling2D()(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)    x = layers.MaxPooling2D()(x)    x = layers.Flatten()(x)    #x = layers.Dropout(0.5)(x)    #x = layers.Dense(128, activation='relu')(x)    #x = layers.Dropout(0.5)(x)    #x = layers.Dense(128, activation='relu')(x)    x = layers.Dropout(0.25)(x)    x = layers.Dense(128, activation='relu')(x)    x = layers.Dropout(0.25)(x)    outputs = layers.Dense(2)(x)        model = keras.Model(inputs=inputs, outputs=outputs, name='basic_cnn')    #model.summary()    #keras.utils.plot_model(model, 'cnn2D_deep_vert.png', show_shapes=False, show_layer_names=False, rankdir='TB')        model.compile(        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),        #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),        #optimizer=keras.optimizers.RMSprop(),        optimizer='adam', # reduce learning rate?        metrics=['accuracy'],    )        if trace:        print('Training CNN 2D Deep')    history = model.fit(train_ds, validation_data=test_ds, epochs=n_epoch, verbose=1)        #if trace:    #    print('Testing CNN 2D')    # test accuracy and lost    #test_accr = model.evaluate(test_ds, verbose=2)        # can't use metric='AUC' with Dense(2)    y_pred = tf.nn.softmax(model.predict(test_ds))[:,1] # sklearn just takes prob of larger label        y_test = []    for x,y in test_ds:        y_test = y_test+y.numpy().tolist()        auc = roc_auc_score(y_test, y_pred)    false_pos, true_pos, thresholds = roc_curve(y_test, y_pred)        roc_data = np.array([false_pos, true_pos, thresholds]).T        m = modelContainer2('cnn2D_deep_model', model, history, roc_data, auc)        return(m)def res2D(n_epoch, batch_size, img_hw, root_dir, trace=False):        [train_ds, test_ds] = make_2D_datasets(batch_size, img_hw, root_dir)        inputs = keras.Input(shape=(img_hw, img_hw, 3))    x = layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1)(inputs)    x = layers.Conv2D(32, 3, activation='relu')(x)    x = layers.Conv2D(32, 3, activation='relu')(x)    block_1_output = layers.MaxPooling2D(3)(x)        x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)    block_1_out_down = layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', activation=None)(block_1_output)    block_1_out_pad = pad_depth(block_1_out_down,64)    block_2_output = layers.add([x, block_1_out_pad])        x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)    block_3_output = layers.add([x, block_2_output])        x = layers.Conv2D(128, 3, activation='relu', padding='same')(block_3_output)    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)    block_3_out_down = layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation=None)(block_3_output)    block_3_out_pad = pad_depth(block_3_out_down,128)    block_4_output = layers.add([x, block_3_out_pad])        x = layers.GlobalAveragePooling2D()(block_4_output)    x = layers.Dropout(0.2)(x)    x = layers.Dense(256, activation='relu')(x)    x = layers.Dropout(0.2)(x)    x = layers.Dense(128, activation='relu')(x)    outputs = layers.Dense(1, activation='sigmoid')(x)        model = keras.Model(inputs, outputs, name='resnet2D')    #model.summary()        base_learning_rate = 0.000005    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),              metrics=['accuracy', 'AUC'])         if trace:        print('Training ResNet 2D')        checkpoint_path = '../saved_models/checkpoints/res2D_1.ckpt'    checkpoint_dir = os.path.dirname(checkpoint_path)        res2D_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,                                                     save_weights_only=True,                                                     verbose=2)        history = model.fit(train_ds, epochs=n_epoch, verbose=1,                        validation_data=test_ds,                        callbacks = [res2D_callback])        model.save('../saved_models/'+'res2D_12_15_1')        loss = history.history['loss']    accr = history.history['accuracy']    auc = history.history['auc']    val_l = history.history['val_loss']    val_a = history.history['val_accuracy']    val_auc=history.history['val_auc']    file_contents = np.array([loss, accr, auc, val_l, val_a, val_auc]).T    filename = '../visualization/plotting_data/'+'res2D_12_15_1'+'_training_history.csv'    file = open(filename, 'w+', newline ='')       with file:        write = csv.writer(file)        write.writerows(file_contents)        #y_pred = tf.nn.softmax(model.predict(test_ds))[:,1] # sklearn just takes prob of larger label        #y_test = []    #for x,y in test_ds:    #    y_test = y_test+y.numpy().tolist()        #auc = roc_auc_score(y_test, y_pred)    #false_pos, true_pos, thresholds = roc_curve(y_test, y_pred)        #roc_data = np.array([false_pos, true_pos, thresholds]).T        m = None #modelContainer('res2D_model', model, history, test_accr, roc_data, auc)        return(m)    